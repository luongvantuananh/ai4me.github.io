---
layout: post 
title: Các metric cơ bản thường dùng trong Machine Learning/ Deep Learning
group: deep_learning
state: publish

---

Nếu bạn là người đã và đang tìm hiểu về ML/DL thì chắc hẳn sẽ nghe qua cụm từ "metric" hay nghe đâu đó là
"mô hình này có độ chính xác 96%", "F1-score của model đạt 91%", vv. Vậy nó là gì,
có tác dụng gì, có những loại nào, thì sau đây hãy cùng nhau tìm hiểu về nó nha. 

Và như thường lệ, đây là bài viết nhằm mục đích tổng hợp kiến thức cho cá nhân mình, vì vậy mình sẽ tổng hợp
từ nhiều nguồn và tài liệu khác nhau nên đôi lúc các bạn có thể sẽ thấy quen quen ở đâu đó :))

Các nội dung chính:

**1. Metrics là gì và tác dụng như thế nào trong bài toán ML/DL ?**

**2. Các loại metric hay dùng**

# ___Chi tiết nội dung___ :
## 1. Metrics là gì và tác dụng như thế nào trong bài toán ML/DL ?
    
Bất kể bạn làm xong một việc gì thì đều cần một thước đo để đánh giá công việc đó xem làm tốt đến đâu,
công cụ để đánh giá đó trong ML/DL được gọi là metric.

## 2. Các loại metric hay dùng

Trước khi đến với các metric, ta sẽ nói qua về confusion matrix, confusion matrix là một bảng thể hiện số lượng các mẫu được dự đoán đúng, sai trong tập test. Đây là 1 ví dụ 1 confusion matrix dự đoán bênh ung thư. Giả sử ta coi trường hợp bệnh ung thư là positive ( Ta quan tâm chỉ số của label nào thì coi nó là positive)
    

<p align="center">
  <img src="/images/metrics/confusion_m.png" />
</p>

Ta thẩy tổng số mẫu = 80+20+55+90 = 245
Trong đó : 
+  TP: Đoán là nhãn positive và dự đoán đó đúng
+  TN: Đoán là nhãn negative và dự đoán đó đúng
+  FN: Đoán là nhãn negative và dự đoán đó sai
+  FP: Đoán là nhãn positvie và dự đoán đó sai

### 2.1 Accuracy 

Có lẽ accuracy là metric được dùng thường xuyên nhất đặc biệt trong các bàn toán phân loại. Accuracy được hiểu
là: 
    Acc =  Tổng số dự đoán đúng/ Tổng số mẫu có trong tập test.

    Acc = (TP + TN) / Tổng số mẫu trong tập test
        = (90+80) / 245
        = 170/ 245

### 2.2 Precesion

Precision = Tổng số dự đoán postive đúng/ Trên tổng số mẫu trong tập test được dự đoán là positive

    Precision = TP/ (TP + FP) 
              = 90/ (90+55)
              = 90/145

Precision càng cao khi tất cả các nhãn đươc dự đoán là positive đều đúng.

Precision dùng khi việc dự đoán sai các mẫu negavtive là rất nguy hiểm. Bạn muốn lọc được mẫu postivie có độ chắc chắn cao, ví dụ lọc mail spam (Nếu coi mail spam là postive)

### 2.3 Recall

Recall = Tổng số dự đoán positive đúng / Trên tổng số mẫu posivate có trong tập test

    Recall = TP/ (TP + FN)
           = 90/(90+20)
           = 90/110

Recall càng cao khi các điểm positvie thực tế bị bỏ sót càng ít.

Recall dùng khi việc dự đoán sai các mẫu postive là rất nguy hiểm, thà lọc nhầm còn hơn bỏ sót,ví dụ dự đoán bệnh nhân ung thư ( Nếu coi bệnh ung thư là positive) . Vì nếu họ không ung thư mà bảo họ ung thư, họ đi xét nghiệm chỗ khác hay thủ công thì ổn. Chứ họ mắc ung thư mà bảo k vấn đề gì, không chạy chữa gì thì sao chịu trách nhiệm nổi, đúng không bạn ?? :))) 

### 2.4 F1-Score

Vậy nếu bạn muốn cân bằng precision và recall thì làm thế nào ? Yên tâm, F1-Score sẽ giúp bạn làm điều đó


    F1-Score = 2/(1/Precision + 1/Recall)
             = 2*Recall*Precision/(Precision + Recall) 


## Lưu ý :

> Thông thường ta hay sử dụng metric accuracy, nhưng
> khi dữ liệu mất cân bằng, thì accuracy
> không đủ độ tin tưởng nữa mà cần phải sử dụng
> các metric khác để đo lường
